{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN using IMDB dataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXqxOMmIX4MH"
      },
      "source": [
        "ANN using IMDB dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFetS5VfQAS7"
      },
      "source": [
        "Calling the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5tDFJKjPzfJ"
      },
      "source": [
        "from tensorflow import keras\r\n",
        "from keras import Sequential\r\n",
        "from keras.preprocessing import sequence\r\n",
        "from keras.datasets import imdb\r\n",
        "from keras.layers import Dense, Flatten, Embedding\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import tensorflow as tf\r\n",
        "import string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWZbgzHJQTK1"
      },
      "source": [
        "Grabbing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9irTVsWQV1W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a8bd355-a369-40a0-8f9a-c25af0d34fda"
      },
      "source": [
        "top_words=10000\r\n",
        "(x_train,y_train),(x_test,y_test)=imdb.load_data(num_words=top_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRpNdqyDYXDs"
      },
      "source": [
        "Viewing the train dataset:\r\n",
        "1=positive review while 0=negative review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0-jJ9RVYas0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2542e787-0491-4eb1-aae6-77f6e25f9ab1"
      },
      "source": [
        "x_train[0]\r\n",
        "y_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7nfnR1jkeKC"
      },
      "source": [
        "Reversing the keys to confirm that they are actually reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LefRMyz-g1VC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5ff5f47-ae8e-48ea-8f65-2ceaa91f5d77"
      },
      "source": [
        "word_dict = imdb.get_word_index() # Forms a dictionary\r\n",
        "word_dict = { key:(value + 3) for key, value in word_dict.items() } \r\n",
        "word_dict[''] = 0 \r\n",
        "# Padding \r\n",
        "word_dict['&amp;amp;amp;gt;'] = 1 \r\n",
        "# Start \r\n",
        "word_dict['?'] = 2 \r\n",
        "# Unknown word \r\n",
        "reverse_word_dict = { value:key for key, value in word_dict.items() } \r\n",
        "print(' '.join(reverse_word_dict[id] for id in x_train[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "&amp;amp;amp;gt; big hair big boobs bad music and a giant safety pin these are the words to best describe this terrible movie i love cheesy horror movies and i've seen hundreds but this had got to be on of the worst ever made the plot is paper thin and ridiculous the acting is an abomination the script is completely laughable the best is the end showdown with the cop and how he worked out who the killer is it's just so damn terribly written the clothes are sickening and funny in equal ? the hair is big lots of boobs ? men wear those cut ? shirts that show off their ? sickening that men actually wore them and the music is just ? trash that plays over and over again in almost every scene there is trashy music boobs and ? taking away bodies and the gym still doesn't close for ? all joking aside this is a truly bad film whose only charm is to look back on the disaster that was the 80's and have a good old laugh at how bad everything was back then\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCmWSUi_nxjj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be770de4-ce04-41f9-b916-dc88d0a48bf6"
      },
      "source": [
        "max_review_length = 150 \r\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=max_review_length) \r\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=max_review_length)\r\n",
        "print(x_train[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   4  249  126   93    4  114    9 2300 1523    5  647    4  116    9\n",
            "   35 8163    4  229    9  340 1322    4  118    9    4  130 4901   19\n",
            "    4 1002    5   89   29  952   46   37    4  455    9   45   43   38\n",
            " 1543 1905  398    4 1649   26 6853    5  163   11 3215    2    4 1153\n",
            "    9  194  775    7 8255    2  349 2637  148  605    2 8003   15  123\n",
            "  125   68    2 6853   15  349  165 4362   98    5    4  228    9   43\n",
            "    2 1157   15  299  120    5  120  174   11  220  175  136   50    9\n",
            " 4373  228 8255    5    2  656  245 2350    5    4 9837  131  152  491\n",
            "   18    2   32 7464 1212   14    9    6  371   78   22  625   64 1382\n",
            "    9    8  168  145   23    4 1690   15   16    4 1355    5   28    6\n",
            "   52  154  462   33   89   78  285   16  145   95]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oTfNJOmp1CM"
      },
      "source": [
        "Building the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Aqn7fMzqBUs"
      },
      "source": [
        "embedding_vector_length = 32\r\n",
        "model = Sequential()\r\n",
        "model.add(Embedding(top_words, embedding_vector_length, input_length=max_review_length))\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(16, activation='relu')) \r\n",
        "model.add(Dense(16, activation='relu'))\r\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mc4jA2cKvW4f"
      },
      "source": [
        "Setting up the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvi1l9StvZXY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ea2b4df-2731-481d-fed7-d42886f57492"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 150, 32)           320000    \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 4800)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16)                76816     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 397,105\n",
            "Trainable params: 397,105\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-gpE9AhwM5a"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSpsT9wqwObT"
      },
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics='acc')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Twf76nvwwa3",
        "outputId": "fe0f26d8-5c9e-4dde-d5f8-b69ba0b02b09"
      },
      "source": [
        " model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "196/196 [==============================] - 3s 10ms/step - loss: 0.6329 - acc: 0.6026 - val_loss: 0.3126 - val_acc: 0.8624\n",
            "Epoch 2/10\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.1995 - acc: 0.9257 - val_loss: 0.3511 - val_acc: 0.8532\n",
            "Epoch 3/10\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.0530 - acc: 0.9895 - val_loss: 0.4152 - val_acc: 0.8535\n",
            "Epoch 4/10\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.0089 - acc: 0.9993 - val_loss: 0.4831 - val_acc: 0.8530\n",
            "Epoch 5/10\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.0027 - acc: 0.9999 - val_loss: 0.5235 - val_acc: 0.8546\n",
            "Epoch 6/10\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 9.7713e-04 - acc: 1.0000 - val_loss: 0.5520 - val_acc: 0.8546\n",
            "Epoch 7/10\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 5.6745e-04 - acc: 1.0000 - val_loss: 0.5769 - val_acc: 0.8551\n",
            "Epoch 8/10\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 3.6401e-04 - acc: 1.0000 - val_loss: 0.5987 - val_acc: 0.8552\n",
            "Epoch 9/10\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 2.5796e-04 - acc: 1.0000 - val_loss: 0.6170 - val_acc: 0.8552\n",
            "Epoch 10/10\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.9034e-04 - acc: 1.0000 - val_loss: 0.6327 - val_acc: 0.8555\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7efe5d3c41d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwUp5pNZAVTm"
      },
      "source": [
        "Testing the model's accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mvRWqv0AXwD",
        "outputId": "7a64db3b-8594-4df5-b8f8-f818d2ecfe2f"
      },
      "source": [
        "_,accuracy=model.evaluate(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 1s 1ms/step - loss: 0.6327 - acc: 0.8555\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdNJd2IUAy4D",
        "outputId": "ecea446d-a6e9-4f72-dd98-7d192593e7cc"
      },
      "source": [
        "accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8554800152778625"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvD3OZgYhvyE"
      },
      "source": [
        "Testing the model with custom input:\r\n",
        " - Preparing the input by removing punctuation characters, converting characters to lower case, and removing words containing numbers \r\n",
        " - Generate an input tensor\r\n",
        " - Invoke the model and return the result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bANfgbpdS1vG"
      },
      "source": [
        "def analyze(text): \r\n",
        "  translator = str.maketrans('', '', string.punctuation) \r\n",
        "  text = text.translate(translator) \r\n",
        "  text = text.lower().split(' ') \r\n",
        "  text = [word for word in text if word.isalpha()] \r\n",
        "  input = [1] \r\n",
        "  for word in text: \r\n",
        "    if word in word_dict and (word_dict[word]['&amp;amp;lt;']):\r\n",
        "      top_words: input.append(word_dict[word]) \r\n",
        "    else: \r\n",
        "       input.append(2)   \r\n",
        "       padded_input = sequence.pad_sequences([input], maxlen=max_review_length) \r\n",
        "       result = model.predict(np.array([padded_input][0]))[0][0] \r\n",
        "       return result"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7249nmPaVW7e"
      },
      "source": [
        "bad_review = analyze(\"That was a terrible movie. I can't watch it again\")\r\n",
        "print(bad_review)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}